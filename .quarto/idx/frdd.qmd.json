{"title":"Fuzzy Regression Discontinuity","markdown":{"headingText":"Fuzzy Regression Discontinuity","containsRefs":false,"markdown":"\n\n```{r setup, include=FALSE}\n\nknitr::opts_chunk$set(\n\techo = TRUE,\n\tmessage = FALSE,\n\twarning = FALSE,\n\tcomment = NA\n)\n\nrm(list = ls())\n#enter <- read.csv(\"enter.csv\")\n```\n\n###  Data\n\\\n\\\n\n```{r, eval=F, echo=T}\n#install.packages(\"downloadthis\")\nlibrary(downloadthis)\n\ndownload_link(\n  link = \"https://bayreuth-politics.github.io/CI22/data/enter.csv\",\n  output_name = \"enter\",\n  output_extension = \".csv\",\n  button_label = \"Lab 9 Data\",\n  button_type = \"success\",\n  has_icon = TRUE,\n  self_contained = TRUE\n)\n\n#download_link(\n#  link = \"https://github.com/dpir-ci/CI22/raw/gh-pages/docs/lectures/lecture8.pdf\",\n#  output_name = \"week8\",\n#  output_extension = \".pdf\",\n#  button_label = \"Lecture Slides\",\n#  button_type = \"default\",\n#  has_icon = FALSE,\n#  self_contained = FALSE\n#)\n```\n\n\\\n\\\n\n---\n\n\n# Recap\n\n### Sharp RDD\n\nLast week we discussed sharp regression discontinuity designs, in which a cut-off perfectly determines the treatment status of units. In simple words: all units on one side of the cut-off are treated, while all units on the other side are not:\n\n$$\n\\operatorname{Pr}\\left(D_{i}=1\\right)=p\\left(X_{i}\\right) \n$$\n\n$$\np\\left(X_{i}\\right)= \\begin{cases}1 & \\text { if } X_{i} \\geq X_{0} \\\\ 0 & \\text { if } X_{i}<X_{0}\\end{cases}\n$$\n\n\n### Fuzzy RDD\n\nWhile sharp RDDs are only a special case of regression discontinuity, RDDs are more powerful than that. __Fuzzy RDDs__ allow us to estimate causal effects in settings where treatment assignment is not deterministic. The cut-off may not perfectly determine treatment exposure, but it creates a _discontinuity in the probability_ of treatment exposure. The cut-off therefore does not perfectly predict treatment status. Still, we can use a fuzzy RDD as long as it introduces a meaningful as-if random discontinuity that we can take advantage of.\n\n$$\n\\begin{aligned}\n\\lim _{X_{i} \\uparrow X_{0}} p\\left(X_{i}\\right) & \\neq \\lim _{X_{i} \\downarrow X_{0}} p\\left(X_{i}\\right) \n\\end{aligned}\n$$\n\nAs we learned before, we cannot simply ignore treatment uptake as it likely is not random: Other (unobserved) covariates might come into play and cause units to take up or reject treatment. In other words, _non-compliance_ with treatment assignment is an issue in this case that must be taken into account in order to estimate an unbiased causal effect - this should have you recall Lab 7.\n\nIn fact, a _fuzzy RDD_ simply incorporates an instrumental variable (IV) that is applied to a regression discontinuity. Usually we can use the treatment assignment - i.e. on which side a unit is of a cut-off - as an instrument for treatment status. Similarly to the IV design, we estimate the _LATE_ among compliers - or _CACE_ at the discontinuity. Note that all assumptions of the IV design need to be satisfied here, too. Extrapolating across the discontinuity, this allows us to estimate the _LATE_ for compliers at the discontinuity (close to the threshold):\n\n$$\n\\begin{aligned}\n\\alpha_{F R D D} &=E\\left[Y_{1}-Y_{0} \\mid X=c  \\right] \\\\\n&=\\frac{\\lim _{x \\downarrow c} E[Y \\mid X=c]-\\lim _{x \\uparrow c} E[Y \\mid X=c]}{\\lim _{x \\downarrow c} E[D \\mid X=c]-\\lim _{x \\uparrow c} E[D \\mid X=c]} \\\\\n&=\\frac{\\text { outcome discontinuity }}{\\text { treatment discontinuity }} \\\\\n& \\approx \\frac{E[Y \\mid Z=1]-E[Y \\mid Z=0]}{E[D \\mid Z=1]-E[D \\mid Z=0]}\n\\end{aligned}\n$$\n\nThis again should sound familiar - the _LATE_ among compliers in fuzzy RDDs can be estimated using a 2SLS regression as we will see in today's Lab.\n\n---\n\n**Before starting this seminar**\n\n1. Create a folder called \"lab9\"\n\n2. Download the data (you can use the button or the one at the top, or read csv files directly from  github): \n\n3. Open an R script (or Markdown file) and save  it in our “lab9” folder.\n\n4. Set your working directory using the setwd() function or by clicking on “More“. For example *setwd(\"~/Desktop/Causal Inference/2022/Lab9\")*\n\n5. Let's install an load packages that we will be using in this lab:\n\n```{r, eval=F, echo=T}\n\nlibrary(rdd) # to conduct a density test\nlibrary(rdrobust) # to conduct non-parametric estimation\nlibrary(rddensity) # to conduct a density test\nlibrary(tidyverse)  # ggplot(), %>%, mutate() \nlibrary(broom)  # Convert models to data frames\nlibrary(rdrobust)  # For robust nonparametric regression discontinuity\nlibrary(estimatr)  # Run 2SLS models in one step with iv_robust()\nlibrary(modelsummary)  # Create side-by-side regression tables\nlibrary(kableExtra)  # Fancy table formatting\nlibrary(ggplot2) # to generate plots\nlibrary(haven) # to import dta files. \nlibrary(wesanderson) # To change the colour scheme of ggplot\n\n```\n\n---\n\n# Seminar Overview\n\nIn this **seminar**, we will cover the following topics:\n\\\n1. Familiarise ourselves with the data structure of fuzzy RDD and the substantive interpretation of the estimator.\n\\\n2. Visualise discontinuities in terms of treatment and outcome at the cut-off.\n\\\n3. Estimate parametric fuzzy RDDs using 2SLS regressions. \n\\\n4. Using the `rdrobust` package to estimate non-parametric fuzzy RDDs.\n\\\n5. Conduct the following robustness/falsification tests such as balance test, placebo outcome and density test. \n\n---\n\n# Staying in the First League: Parliamentary Representation and the Electoral Success of Small Parties\n\nTo familiarize ourselves with fuzzy RDDs, we will be analysing data from  the paper [Staying in the First League: Parliamentary Representation and the Electoral Success of Small Parties](https://core.ac.uk/download/pdf/71804766.pdf) authored by Elias Dinas, Pedro Riera and Nasos Roussias.\n\nIn this paper, the authors seek to contribute to answering one of the most essential research questions in party politics: Why are some small parties successful whereas other whither away? What accounts for the variation in the trajectories of small parties?\n\nThe authors theorise an organisational mechanism that contributes to parties' success. According to their expectations, _entering parliament_ should lead to an increase in a party's vote share in the subsequent election. This is because being represented in parliament usually comes with a lot of benefits, which are not experienced by parties that are not represented: influence on policy-making, public funding, media visibility, an increase in organisational capacity (staff, etc.) as well as reduced uncertainty about electoral viability and ideological profiles. Conversely, parties that fail to enter parliament do not gain these benefits and might even be abandoned by promising personnel. As you notice, there might be a lot of reasons which make it difficult to isolate a causal effect without an appropriate identification strategy. \n\nIn many multi-party systems, there is a legal threshold for representation in parliament at the national level, usually in terms of a fixed vote share, that determined whether a party enters parliament or not. The authors exploit the randomness introduced by these electoral thresholds to circumvent endogeneity problems. Clearly, parties are not able to manipulate their vote share - at least in democracies. The authors look at countries that had employed a legal threshold of representation at the national level at least one since 1945.\n\n__Why do we need to estimate a _fuzzy RDD_ here?__ Unlike the sharp RDD, in this case some candidates make it to parliament even though their party did not pass the threshold - in other words, there is non-compliance with treatment assignment as the discontinuity does not fully determine treatment status. Roughly 20% of electoral systems allow some parties to get into parliament even if they did not meet the threshold - can you think of reasons why?\n\nThe authors use a linear regression estimator with a triangular kernel and optimal bandwidths determined by Imbens/Kalyanaramn's algorithm (h=2.4, after the cut-off is centred). The outcome is parties' vote share at the subsequent election ($t_1$). They find a local average treatment effect among compliers of 1.9%-points: Parties that have not cleared the threshold received 3.9 percent at election $t_1$, whereas those who overcome the threshold get 5.8 percent. This amounts to a meaningful and substantive effect of an increase of around 40% in their vote share.\n\n_Note: Electoral thresholds vary by country, ranging from 0.67%-points to 10%-points. To make observations comparable, the authors standardise electoral results. They use 3.51 as common cut-off point and transform vote shares to that scale. Importantly, the relative distance from the threshold remains the same:_ \n\n$$\\frac{Vote Share_i}{Threshold_i} = \\frac{VoteShare_{i, standardised}}{3.51} $$ \n\n\nWe will be using the following variables: \n\n| Variable             \t| Description                                                                              \t|\n|------------------\t|------------------------------------------------------------------------------------------\t|\n| ```performance``` \t| This is the _standardised and centred_ vote share of party _i_ at $t_0$.      \t|\n|```treat```| Binary variable that indicates whether the party's vote share met/exceeded the threshold (=1) or not (=0). \t|\n| ```newsuccess```   | The party's vote share in the subsequent election at $t_1$.\t|\n| ```treated``` |  Binary variable indicating whether a party entered parliament (=1) or not (=0)        \t|\n| ```oldsuccess```         \t|  The _standardised and centred_ vote share of party _i_ at $t_{(-1)}$, which we'll use as a placebo.\t                              \t|\n|```newperc``` | Indicates the standardised vote share in absolute terms  |\n|```seats``` | Indicates the number of seats won in an election  |\n| ```established```| Binary variable indicating if a country is an established democracy |\n| ```oldparty```| Count variable indicating how many elections a party had contested before. |\n\n---\n\nNow let's load the data. There are two ways to do this: \n\nYou can load the brands dataset from your laptop using the `read.csv()` function.  You can call this data set `enter`.\n\n\n```{r, eval=F, echo=T}\n# Set your working directory\n#setwd(\"~/Desktop/Causal Inference/2022/Lab9\")\n# \nlibrary(readr)\nenter <- read.csv(\"https://bayreuth-politics.github.io/CI22/data/enter.csv\")\n\n#head(enter)\n```\n\n---\n\nNow, let's see how the data looks like. Generate a plot using the `rdplot()` function from the `rdrobust` package.\n\nThe syntax is quite simple - see it:\n\n**Exercise 1: Generate a plot using the `rdplot(Y, X, ci = 95, binselect = \"\", subset = condition)` function. Replace X with `enter$performance` and Y with `enter$newsuccess`. Set the argument `ci` equal to 95, so we can display confidence interval in each bin. Let's create a RD plot with evenly-spaced bins by setting the argument `binselect` equal to \"es\". Finally, let's subset the data for parties whose standardised vote share was below 3.51. For this, set the argument `subset` equal to `performance < 3.51`. For more details about this function please see below. **\n\n\n```{r, eval=F, echo=T}\nrdplot(Y, X, c = 0, ci = 95, binselect = \"es\", subset = Z < condition)\n```\n\n\n| Function/argument \t| Description \t|\n|---\t|---\t|\n| Y \t| Y is the dependent variable. \t|\n| X \t| X is the running variable \t|\n| c \t| To specify the cut-off the default is 0 \t|\n| ci \t| Optional graphical option to display confidence intervals of selected level for each bin \t|\n| binselect \t| Specifies the procedure to select the number of bins. See options below:  \t|\n|  \t| **es: IMSE-optimal evenly-spaced method using spacings estimators.** \t|\n|  \t| esmv: mimicking variance evenly-spaced method using spacings estimators. This is the default option. \t|\n|  \t| qspr: IMSE-optimal quantile-spaced method using polynomial regression. \t|\n| subset \t| an optional vector specifying a subset of observations to be used. \t|\n\n\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n\n```{r, eval=F, echo=T}\nrdplot(enter$newsuccess, enter$performance, ci=95, binselect=\"es\", subset = enter$performance <3.51) \n\n```\n\nNote that it might make sense to look at the discontinuity in terms of the treatment, too. This will give us a (visual) indication of whether the discontinuity in terms of treatment status is meaningful. You can simply use the `rdplot` command to do this.\n\\\n\n```{r, eval=F, echo=T}\nrdplot(enter$treated, enter$performance, ci=95, binselect=\"es\", subset = enter$performance <3.51) \n```\n\nAs expected, we have perfect compliance above the threshold - and rather strong yet imperfect compliance below the threshold.\n\n</details> \n\n\\\n\n\nNote that we use 3.51 to drop observations larger than that number (weighted threshold). This insures a balanced N below and above the cut-off. While the running variable is standardised, it cannot take on values smaller than 0 (which would correspond to  a 0% vote share). To account for this, we mirror this natural boundary above the threshold.\n\nLet's check that this indeed a fuzzy design. To do so let's first create a new variable called `treatment_received`.\n\n\n**Exercise 2: Create a new variable that is equal to \"Treated\" if the `treated` variable is equal to 1, and \"Not treated\" otherwise. You can use the `mutate()` and `ifelse()` function to do this. You can see an example below.**\n\n```{r, eval=F, echo=T}\ndata <- data %>% \n  mutate(new_variable = ifelse(variable == 1, \"Treated\", \"Not treated\"))\n\n```\n\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n\n```{r, eval=F, echo=T}\nenter <- enter %>% \n  dplyr::mutate(treatment_received = ifelse(treated == 1, \"Treated\", \"Not treated\"))\n\ntable(enter$treatment_received)\n```\n\n</details> \n\n\\\n\n\nNow that we have created this variable, let's use it to generate other RD plots that will help us identify whether the units actually received the treatment condition that they were assigned to. Let's use ggplot this time. \n\\\n\n**Exercise 3: Generate the following plot:**\n\n-  Map data components into the graph `ggplot(aes(x = running variable, y = outcome, colour = as.factor(new received variable)), subset(subset=running variable <3.51), data = data)`\n\n- Add a scatter plot by adding the following function: `geom_point(size = , alpha = )`. Set the `size` argument equal to 1 and the `alpha` argument equal to 0.6.\n\n- Add a linear regression below the threshold using: `geom_smooth(data = filter(subset(data,subset=running variable <3.51), running variable <= 0), method = \"lm\")` \n\n- Add a linear regression above the threshold using: `geom_smooth(data = filter(subset(data,subset=running variable <3.51), running variable > 0), method = \"lm\")` \n\n- Add vertical that pass through 0 on the vertical axis by setting the `intercept` equal to 0:  `geom_vline(xintercept = 0)` \n\n- Change the labels on the y and x axis using: `labs(x = \"Vote share t0\", y = \"Vote share t1\", color = \"Treated\")` \n\n- Change the default colours adding the Wes Anderson palette: `scale_color_manual(values=wes_palette(\"Darjeeling1\"))`\n\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n\n\n```{r, eval=F, echo=T}\n\nggplot(subset(enter, subset=performance<3.51), aes(x = performance, y = newsuccess, color = as.factor(treatment_received))) +\n  # Make points small and semi-transparent since there are lots of them\n  geom_point(size = 1, alpha = 0.5) + \n  #  Add a line based on a linear model for the parties meeting the threshold\n  geom_smooth(data = filter(subset(enter,subset=performance <3.51), performance <= 0), method = \"lm\") +\n  # Add a line based on a linear model for the parties missing the threshold\n geom_smooth(data = filter(subset(enter,subset=performance <3.51), performance > 0), method = \"lm\") +\n  # Add labels\n  geom_vline(xintercept = 0) +\n  labs(x = \"Vote share t0\", y = \"Vote share t1\", color = \"Treated\") +          scale_color_manual(values=wes_palette(\"Darjeeling1\")) # change the defaults palette. \n```\n\\\nFrom a quick visual inspection, we can see that we are dealing with a case of one-sided non-compliance. This means that some parties that were below the threshold entered parliament nonetheless - this is what we would expect. Conversely, every party that met its respective threshold entered parliament - as it should be.\n\n</details> \n\n\\\n\n\nLet's now calculate the proportion of compliers above and below the threshold, just to know more about the extent of non-compliance we are dealing with. \n\n**Exercise 4: Calculate the proportion of compliers above and below the threshold. Use the instructions and functions below to do this.**\n\n```{r, eval=F, echo=T}\ndata %>%  \n  group_by(variable1, variable2) %>%  # \n  summarise(count = n()) %>% \n  group_by(variable1) %>% \n  mutate(prop  = count/ sum(count))\n```\n \n - Group observations by using the `group_by()` function and include the following variables: `treated` and `performance<=0`. By executing this operation, we are is creating four groups: 1) Parties elected/above the threshold; 2) Parties elected/below the threshold; 3) Non elected parties/above the threshold; 4) Non elected parties/below the threshold. \n \n - Add the `summarise()` function and create a new data frame from the grouping data frame we created before. Add `count` inside of the summarise function. This will be a variable that will store the number of observations in each group. For this, we need to add the `n()` function that calculates the number of observations in each group. By adding the two functions below, we get the number of observations in each of the four groups (feel free to run just these two lines and see what you get). \n \n - Finally, let's calculate the _proportion_ of compliers above and below the threshold. We can do this by grouping observations by their treatment condition and then using the `sum()` function.  We can create a new variable called `prop`. It is based on the number of observations in each sub-group (whether they were above or below the threshold). Then, we divide this number by the total number of observations within each treatment condition using the  `sum(count)` function. This will give you the proportion of compliance.\n \nMore detail of these function can be found below: \n\n| Function/argument \t| Description \t|\n|---\t|---\t|\n| group_by() \t| Groups observations by the variables included in the function  \t|\n| summarise() \t| Creates a new data frame. It will have one (or more) rows for each combination of grouping variables \t|\n| n() \t| returns the number of observations in a current group \t|\n| sum() \t| returns the sum of all the values present in its arguments \t|\n\n\n\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n\n```{r, eval=F, echo=T}\nenter %>% \n  group_by(treated, performance <= 0) %>% \n  summarize(count = n()) %>% \n  group_by(treated) %>% \n  mutate(prop  = count/ sum(count))\n```\nWe can see the count and proportion of compliance in each group. We see that 176 times parties were below the threshold, but end up in parliament (around `10\\%` of the observations). We can confirm that we have a case of one-sided non-compliance. \n\n</details> \n\n\\\n\n---\n\nLet's subset the data for the following analyses. We want to make sure we have a fair comparison between observations below and above the cut-off. Since the `performance` variable cannot have outcomes `<-3,51`, we mirror the data by subsetting positive performance scores: \n\n```{r, eval=F, echo=T}\nenter=enter[enter$performance<3.51,]\n```\n---\n\n\n### Fuzzy RDD: Parametric Estimation\n\n\nAs last week, let's estimate a parametric fuzzy RDD first to make sure we understand the underlying logic - which is based on the instrumental variables design. Remember that in the case of _fuzzy RDDs_ we have 'two events' of interest. First, __'treatment assignment'__ which is defined by the running variable exceeding the cut-off, and, secondly, actual __treatment status__. Let formally state that $Z_i$ is an indicator for when $X_{i,\\text{centered}}$ exceeds the cut-off. We can then use this variable to  instrument for the endogenous treatment variable $D_{i}$.\n\\\n\nThe principle is the same as in the IV design: We have an instrument, $Z_i$, that describes assignment to treatment based on an observation's position relative to the cut-off. We know that the instrument is a strong predictor - as it should be - of the treatment status, $D_i$. We can therefore exploit the random variation (close to the cut-off) introduced by the instrument to predict treatment status in our _first stage_ - which you can think of as indicating compliance with the treatment assignment or describing the discontinuity in the probability of receiving treatment:\n\n$$\\hat{D_i} = \\gamma_0 + \\gamma_1 X_{i,centered} + \\gamma_2 Z_i + \\rho_i$$ for $$c-h \\leq X_i \\leq c + h$$ \n\nHere, in a simple linear model with a single slope $\\hat{D}$ predicts the treatment status based on assignment to the treatment, ($Z_i$), and the vote share ($X_{i,centered}$) in $t_0$. \n\nThe second stage, then, uses the predicted values to calculate the following equation in order to estimate the LATE among compliers at the cut-off:\n\n$$\\hat{Y_i} = \\beta_0 + \\beta_1 X_{i,centered} + \\beta_2 \\hat{D_i} + \\epsilon_i$$ for $$c-h \\leq X_i \\leq c + h$$\n\nOur coefficient of interest is $\\beta_2$, which is the Local Average Treatment Effect ('LATE') among compliers at the cut-off. Having this in mind,  we know we can estimate a parametric fuzzy RDD by specifying a 2SLS regression. This can be done using the packages and commands you already know, such as `iv_robust()`.\n\\\n\n**Exercise 5: Estimate a parametric fuzzy RDD model using the `iv_robust()` command. Interpret your findings. **\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n```{r, eval=F, echo=T}\nmodel_fuzzy <- iv_robust(\n  newsuccess ~ treated + performance | treat + performance,\n  data = filter(enter)\n)\nsummary(model_fuzzy)\n```\n\nSpecifying the 2SLS model, we find that the estimated effect is `1.65%-points` on the _standardised scale_. The estimate is also statistically significant, so we conclude that the estimated LATE among compliers is meaningfully different from `0`.\n\\\n\nIs this estimate robust though? The global parametric estimation has significant weaknesses. Think of our identification assumption for the RDD. In this global model, we have been using _all_ observations from the data frame, including those rather far away from the threshold - i.e. those which are not really comparable. Moreover, the parametric model, unlike kernel estimators, does not weigh observations. Accordingly, the bias introduced by including the whole range of data is possibly severe. We might have estimated a biased effect here. \n</details> \n\\\n\nLet's tackle this problem by estimating a more credible parametric fuzzy RDD. We can do so by subsetting the data we input into the regression model.\n\n**Exercise 6: Estimate the same model as above, but only consider parties with vote shares up to `1%` on the standardised scale below/above the threshold. Is this result more credible? **\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n```{r, eval=F, echo=T}\nmodel_fuzzy_range <- iv_robust(\n  newsuccess ~ treated + performance | treat + performance,\n  data = filter(enter, performance <= 1, performance>-1)\n)\nsummary(model_fuzzy_range)\n```\n\\\n\nThis estimator draws a different picture. Our estimated effect is now `2.93%-points` on the standardised scale - this is meaningful and almost as large in magnitude as the standardised threshold itself. The estimate is also statistically significant. Based on this model specification, we can conclude that the LATE among compliers at the cut-off  indeed is meaningful. \n\\\n\nThis model is somewhat more credible than the one we estimated above. Now we are only looking at observations which represent parties with a vote share of up to `1%-point` above or below the standardised threshold. This is more reasonable as as these parties should be more comparable. In fact, we find that wihtin this range the actual vote share (`performance`) does not predict the result of the subsequent election in any meaningful way. Within this rather small window, entering parliament drives variation in the subsequent election. \\\n\nNote that the model still has some disadvantages: We specify the functional form of the model and still do not weigh observations based on their distance to the cut-off. Estimating non-parametric models helps us calculate even more robust estimates.\n\n</details> \n\n\\\n\n---\n\n### Non-Parametric Fuzzy RDD Estimation\n\nIn a first step, let's 'emulate' the parametric model we just specified - this time estimating a non-parametric model. \\\n\nFuzzy estimation with `rdrobust` is - thankfully - relatively straightforward. The syntax is essentially the same as in the case of sharp RDDs, obviously with the exception that we need to specify that our model is supposed to estimate a fuzzy RDD. We can do so using the `fuzzy=` argument to specify the treatment status (`treated` in our case). Importantly, you do not need to specify an instrument (or even create one!). All you need to specify is the column that indicates treatment status, the running variable and the cut-off — `rdrobust` will do all the above/below-the-cut-off instrument stuff behind the scenes for you.\n\n\n**Exercise 7: Estimate a non-parametric fuzzy RDD with a bandwidth of `h=1` and uniform kernel. **\n\\\n\nThe syntax of `rdrobust` is pretty similar to the sharp RDD. Recall that the argument `c` specifies the cut-off, while `h` determines the bandwidth. The `fuzzy` argument is sufficient to have `rdrobust` estimate a fuzzy model.\n\\\n\n```{r, eval=F, echo=T}\n\nsummary(rdrobust(outcome, running_var, c=, fuzzy=treatment_status,   h=))\n\n```\n\n<details>\n  <summary>*Reveal Answer*</summary>\n```{r, eval=F, echo=T}\nsummary(rdrobust(enter$newsuccess, enter$performance, c=0, fuzzy=enter$treated,  kernel=\"uniform\", h=1))\n```\n\\\n\nHow does that look like? The estimated effect is pretty similar to the one from our (narrow) parametric estimation. Conventional measures of uncertainty also indicate that the effect is significant - looking at the robust p-values and confidence intervals, however, reveals that we would _not_ reject the null hypothesis based on the robust estimation - which we should base our conclusion on. Here, we find that there is no significant LATE among compliers.  \n\n</details> \n\\\n\nAs we know, `rdrobust`allows us to specify more appropriate models to estimate our treatment effect. Let's now make use of these opportunities to run more precise models.\n\\\n\n**Exercise 8: Estimate the treatment effect, specifying a triangular kernel and a MSE-optimal bandwidth. Also, cluster standard errors by country using the `cluster=` argument. **\n\\\n\n_Note: You can simply add the `cluster` argument and enter the relevant cluster variable. Recall that optimal bandwidths are specified using the `bwselect` argument instead of `h`._\n\n<details>\n  <summary>*Reveal Answer*</summary>\n```{r, eval=F, echo=T}\nsummary(rdrobust(enter$newsuccess, enter$performance, c=0, fuzzy=enter$treated,  kernel=\"triangular\", cluster=enter$countrycode, bwselect=\"mserd\"))\n```\n\\\n\nWe see that the MSE-optimal bandwidth corresponds to `1.13%-points` on the standardised scale on either side of the cut-off.\n\\\n\nThe estimated LATE among compliers is `1.86`, not that different from our previous point estimates. Under this model specification, we find that the estimated effect is not statistically significant - the robust confidence interval includes zero, so we cannot conclude that there indeed is a significant effect of entering parliament on parties' vote share in the subsequent election.\n\\\n\nNote that this model uses a triangular kernel and accounts for non-independence among observations in the same country - for which reason it is somehwat  more convincing compared to the models we estimated before.\n\n</details> \n\n\\\n\nWe can also include covariates. The `rdrobust` package is very flexible in this regard and makes it easy to adjust for them. You can simply add the argument `covs=` and specify the variables you want the model to include.\n\\\n\n**Exercise 9: Specify a non-parametric fuzzy RDD with MSE-optimal bandwidth, clustered standard errors and `seats` and `newperc` as covariates. Interpret your result.  **\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n```{r, eval=F, echo=T}\nsummary(rdrobust(enter$newsuccess, enter$performance, c=0, fuzzy=enter$treated,  kernel=\"triangular\", cluster=enter$countrycode, covs= enter$seats + enter$newperc,  bwselect=\"mserd\"))\n```\n\nThis again looks interesting - the optimal bandwidth hasn't changed much, nor did the magnitude of the estimated treatment effect. Similarly to the model we estimated in the exercise before, however, the treatment effect is not statistically significant to robust estimations. \n\\\n</details> \n\n\\\n\n---\n\n### Sensitivity to Bandwidth\n\nCan we be sure our estimated effect is robust to changing the bandwidth? Let's see if the estimated effect varies meaningfully. As last week, let's plot the effect over changing bandwidths.\n\n**Exercise 10: Plot the estimated effect and 95% confidence intervals for the model specification from the previous exercise over bandwidths ranging from `0.1` to `3.5` in `0.1%-points` intervals.  **\n\\\n\n_Note: You migth want to use the following approach_\n\n- _Create a data frame with all variables you need for the plot and a and observation for each bandwidth._\n\n- _Extract the values from the rdrobust output which you need for your plot._\n\n- _Loop the regression and the extraction of output over the bandwidths indicated in the initial data frame._\n\n- _Save the output in your loop to the respective row in the data frame._\n\n- _Plot the output from the newly created data frame._\n\n<details>\n  <summary>*Reveal Answer*</summary>\n```{r, eval=F, echo=T}\n\nbandwidth <-  seq(from = 0.1, to = 3.5, by = 0.1)  #create a vector with values for each bandwidth you want to estimate\n\ncoefficient<- NA \nse <- NA\nobs <- NA\nbw <- NA\nci_u <- NA\nci_l <- NA\n\ndata_extract <- data.frame(bandwidth, coefficient, se, obs, bw, ci_u, ci_l) # create a data.frame with all variables you want to include in your data set\n\n# create a loop for each bandwidth that is indicated by 'i'\nfor(i in bandwidth){\n  rdbw <- rdrobust(enter$newsuccess, enter$performance, c=0, fuzzy=enter$treated,  kernel=\"triangular\", cluster=enter$countrycode, covs= enter$seats + enter$newperc, h=i) # run the model\n  # extract the model output (make sure to extract *robust* statistics)\n  data_extract$coefficient[data_extract$bandwidth==i]  <- rdbw$coef[3] \n  data_extract$se[data_extract$bandwidth==i]  <- rdbw$se[3]\n  data_extract$obs[data_extract$bandwidth==i]  <- (rdbw$N_h[1] + rdbw$N_h[2]) \n  data_extract$bw[data_extract$bandwidth==i]  <- (rdbw$bws[1, 1]) \n  data_extract$ci_l[data_extract$bandwidth==i]  <- rdbw$ci[3,1]\n  data_extract$ci_u[data_extract$bandwidth==i]  <- rdbw$ci[3,2]\n}\n\n# Make sure the coefficient (and all other values) are numeric\ndata_extract$coefficient  <- as.numeric(data_extract$coefficient)\n\n# Plot the estimates across bandwidths\nggplot(data = data_extract,\n       aes(x = bandwidth, y = coefficient)) +\n  geom_point(size = 0.8) +\n  geom_ribbon(aes(ymin = ci_l, ymax = ci_u), alpha = 0.2) +\n  geom_hline(aes(yintercept = 0), col = \"red\", linetype = 2) +\n  coord_cartesian(ylim = c(-7.5, 7.5)) +\n  theme_minimal() +\n  labs(y = \"LATE among Compliers at Discontinuity\", x = \"Bandwidths (Vote Margin)\")\n\n```\n\\\n\nThis looks interesting - the estimate varies vastly for very narrow bandwidths, but this is expected given the small number of observations that are close around the threshold. This is not uncommon to see. However, it even looks like there is almost a significant _negative_ treatment effect for bandwidths around `0.5%-points`. Our estimated _positive_ treatment effect is robust to all bandwidths starting from around `2.6%` the end of the range.  We can be confident that the effect is not contingent on specific bandwidths. What do we conclude?\n\n</details> \n\n\\\n\nAre we  reasonably confident that there is a significant effect of entering parliament at $t_0$ on a party's vote share in the subsequent election ($t_1$)? What would be the effect in substantive terms though?\n\\\n\nWe know that the threshold (and parties' vote shares) have been standardised, with the standardised threshold being at `3.51%-points`. We can now write a function to convert the standardised (or synthetic) scale into substantive vote shares based on a country's electoral threshold:\n\\\n\n```{r, eval=F, echo=T}\nstandardised_to_vote <- function(coef, threshold) {\n  vote_share <- coef*threshold/3.51\n  return(vote_share)\n}\n```\n\n**Exercise 11: Based on the treatment effect from our previous model from Exercise 9 (`2.057`), calculate the substantive treatment effect in Turkey, Greece and a country of your choice. For this exercise, let's forget that the estimated effect was not statistically significant - we just want to get an impression of its magnitude. **\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n```{r, eval=F, echo=T}\n# In Turkey, the threshold is 10%\nstandardised_to_vote(2.057, 10)\n\n# In Greece, there's only a 3% threshold \nstandardised_to_vote(2.057, 3)\n\n```\n\nRecall that standardisation means that we are estimating the effect relative to the threshold. Accordingly, we will get different substantive results for countries with different absolute thresholds. The substantive effect will be roughly $\\frac{6}{10}$ of the size of the threshold (because `2.057`/`3.51` $\\approx$ 0.6). \n\\\n\nWe find that the substantive gain of entering parliament in Turkey corresponds to an increase of `5.86%-points` in  the subsequent election, whereas it amounts to `1.76%-points` in Greece. What about the other country you chose?\n\n</details> \n\n\\\n\n---\n\n## Falsification tests: \n\n## Placebo outcomes: \n\nWe can conduct multiple tests to find evidence that there is no manipulation of the score around the cut-off. If units cannot precisely manipulate their scores, therefore we should expect no differences in terms of covariates for units above and below the threshold (we will test this later). We should also expect that there should not be differences in outcomes that should not be affected by the treatment. These outcomes are sometimes called  'pseudo-outcome' in the RDD literature. \n\nOne pseudo-outcome that we can use in this study is electoral success (standardised vote share) in the previous election ($t_{-1}$). The idea here is that current parliamentary representation in period ($t_0$) would not affect electoral performance in $t_{-1}$. Let's see if this is true. \n\n**Exercise 12: Conduct a placebo outcome test using the placebo outcome variable `oldsuccess`. Use the `rdrobust()` function to perform this test. Set the argument `bwselect` equal to \"mserd\". Set the cut-off argument `c` equal to zero. Use the `summary()` command to report the results. What can you conclude based on this test? Does the evidence support the continuity assumption?**\n\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n\n```{r, eval=F, echo=T}\n\nsummary(rdrobust(enter$oldsuccess, enter$performance, c=0, bwselect=\"mserd\"))\n\n```\n\nWe find that the local regression estimate is `-1.713` and the robust confidence interval goes from `-5.158` to `2.153` (and the p-value is `0.420`). We find that there no is evidence of manipulation of the running variable around the cut-off with respect ot previous electoral results.  \n\n</details> \n\n\\\n\n### Placebo cut-offs\n\nAs we did last week, we can conduct a placebo cut-off test. This test implies looking at the outcome variable but using different cut-offs where we should not expect changes in the outcome. Thus, the estimates from this test should be near zero (and not statistically significant). Again, one **important** step to conduct this test is subsetting the sample for those observations that are above the cut-off and those that are below. We do this to avoid 'contamination' due to the real treatment effect. It also ensures that the analysis of each placebo cut-off is conducted using only observations with the same treatment status. \n\nRather than subsetting the data and creating a new data frame, let's use the `subset` argument in the `rdrobust()` function. \n\n**Exercise 13: Conduct a placebo cut-off test using `-2.95` for the placebo tests below the cut-off. Use the `rdrobust()` function to perform this test. Set the argument `bwselect` equal to \"mserd\". Replace the cut-off argument `c` with the value of the placebo cut-off. Add the `subset` argument and set it equal to `data$performance < 0 & data$performance >-3.51.  Use the `summary()` command to report the results. What can you conclude based on this test? Does the evidence support the continuity assumption?**\n\n\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n  \n```{r, eval=F, echo=T}\nsummary(rdrobust(enter$newsuccess, enter$performance, c = -2.95, fuzzy=enter$treated, cluster=enter$countrycode,\n                 bwselect=\"mserd\", subset=enter$performance < 0 & enter$performance >= -3.51))\n```\n\nWe find that the RD estimate is `-0.100`, which is pretty small. Also, the robust confidence interval reaches from `-17.186` to `14.109`, which clearly includes zero. Thus, this coefficient is not statistically significant. This provides evidence in favour of continuity assumption. \n\n</details> \n\n\\\n\n### Sorting\n\nAs we covered last week, the key identification assumption of RDDs is that there is no _sorting_ on the running variable. That is, the running variable must be continuous around the threshold. We can do this using _density checks_. This means we're looking at the density of the running variable. Let's again use the `rddensity` package to do so. \n\n\n**Exercise 14: Examine the density of the running variable using the `rddensity` command. Interpret your findings. See an example of the syntax below: **\n\nDoing this is pretty straightforward. You only have to insert the running variable as an argument and, if different from 0, the cut-off. Note that you can optionally specify bandwidths, as above, using the `h` argument. Otherwise, an optimal bandwidth will be specified automatically. You can then save this as an object and run the `summary` command to see the output.\n\n\n```{r, eval=F, echo=T}\nrdd <- rddensity(data$running_variable, c=0)\nsummary(rdd)\n\n```\n\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n```{r, eval=F, echo=T}\nrdd <- rddensity(enter$performance, c=0)\nsummary(rdd)\n\n```\n\nThis test reveals a p-value of `0.3239`. The null hypothesis of this test is that observations near the cut-off are allocated with a 0.5 probability. Given that we failed to reject the null hypothesis, we can claim there is no evidence of sorting around the cut-off. \n\n</details> \n\n\\\n\nLet's now plot this density test like we did last week.  Let's again use the `rdplotdensity` function.  Remember that this function uses the output from the `rddensity` command. The syntax is simple:\n\n\n```{r, eval=F, echo=T}\nrdplotdensity([rdd_object] ,[running_var])\n```\n\\\nAnd these the arguments that you can use. \n\\\n\n| Argument          | Description          |\n|----------------------------|----------------------|\n| ```plotRange```               | Indicates starting and end point of plot  |\n| ```plotN```               | Number of grid points used on either side of the cut-off  |\n| ```CIuniform```               | True or False. If true, CI are displayed as continuous bands |\n\n\\\n\n**Exercise 15: Use the `rplotdensity` to conduct a visual density check. Set the`plotRange` function equal to `c(-2,2)`. Set the `plotN` argument equal to `25`. Finally set the `CIuniform` equal to TRUE.**\n\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n```{r, eval=F, echo=T}\nplot_rdd <- rdplotdensity(rdd, enter$performance, plotRange = c(-2, 2), plotN = 25,  CIuniform = TRUE)\n```\n\\\n\nAgain, we find visual evidence for continuity around the cut-off. Now we can be confident about sorting not being a problem in this data. \n\nYou can also conduct the same test using the `DCdensity` function from the `rdd` package. Unfortunately, to use this command, you need to drop the observations with missing values. You can use  `drop_na(running_variable)` function to do this. \n\n\n</details> \n\n\\\n\n## Balance \n\nLet's finally conduct a balance test to examine whether near the cut-off treated units are similar to control units in terms of observable characteristics.  Ideally, we should get an RD estimate, $\\tau_{RD}$, which is equal to zero.\n\n**Exercise 16: Let's check for balance around the cut-off. Use the `rdrobust()` function. Set the cut-off argument `c` equal to 0, and the `bwselect` argument equal to \"mserd\". In this case, the outcome variables are the covariates that we want to check for balance. Check if there is balance for the covariate `oldparty`, which is the 'age' of the party in terms of previously contested elections. Remember to use the `summary()` command.**\n\n\\\n\n<details>\n  <summary>*Reveal Answer*</summary>\n\n```{r, eval=F, echo=T}\n\nsummary(rdrobust(enter$oldparty, enter$performance, c=0, bwselect=\"mserd\"))\n\n```\n\nWe observe that there is balance for the covariates as it should be. \n\n</details> \n\\\n","srcMarkdownNoYaml":""},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"frdd.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","book":{"title":"Causal Inference","author":"Felipe Torres Raposo","date":"18/09/2024","chapters":["index.qmd","intro.qmd","experiments.qmd","matching.qmd","iv.qmd","diff.qmd","panel.qmd","rdd.qmd","frdd.qmd","summary.qmd","references.qmd"]},"bibliography":["references.bib"],"editor":"visual","theme":"flatly"},"extensions":{"book":{"multiFile":true}}},"pdf":{"identifier":{"display-name":"PDF","target-format":"pdf","base-format":"pdf"},"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"frdd.pdf"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"block-headings":true,"book":{"title":"Causal Inference","author":"Felipe Torres Raposo","date":"18/09/2024","chapters":["index.qmd","intro.qmd","experiments.qmd","matching.qmd","iv.qmd","diff.qmd","panel.qmd","rdd.qmd","frdd.qmd","summary.qmd","references.qmd"]},"bibliography":["references.bib"],"editor":"visual","documentclass":"scrreprt"},"extensions":{"book":{"selfContainedOutput":true}}}},"projectFormats":["html","pdf"]}